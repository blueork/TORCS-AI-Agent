{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06cfe969",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952a6724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset class\n",
    "class TORCSDataset(Dataset):\n",
    "    def __init__(self, csv_file, sensor_cols, continuous_cols, discrete_cols):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.sensor_cols = [col for col in self.data.columns if col in sensor_cols]\n",
    "        # self.sensor_cols = sensor_cols\n",
    "        self.continuous_cols = [col for col in self.data.columns if col in continuous_cols]\n",
    "        # self.continuous_cols = continuous_cols\n",
    "        self.discrete_cols = [col for col in self.data.columns if col in discrete_cols]\n",
    "        # self.discrete_cols = discrete_cols\n",
    "        self.features = torch.tensor(self.data[self.sensor_cols].values, dtype=torch.float32)\n",
    "        self.continuous_labels = torch.tensor(self.data[self.continuous_cols].values, dtype=torch.float32)\n",
    "        self.gear_labels = torch.tensor(self.data['Gear'].values, dtype=torch.long)\n",
    "        self.clutch_labels = torch.tensor(self.data['Clutch'].values, dtype=torch.long)\n",
    "        # Adjust Gear/Clutch to zero-based indexing\n",
    "        self.gear_labels = self.gear_labels - self.gear_labels.min()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.features[idx], self.continuous_labels[idx], \n",
    "                self.gear_labels[idx], self.clutch_labels[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96a4c6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network Model\n",
    "class TORCSNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_gear_classes, num_clutch_classes):\n",
    "        super(TORCSNet, self).__init__()\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU()\n",
    "            # To add a third hidden layer, uncomment:\n",
    "            # nn.Linear(hidden_size, hidden_size),\n",
    "            # nn.ReLU()\n",
    "        )\n",
    "        self.continuous_head = nn.Linear(hidden_size, 3)  # Acceleration, Braking, Steering\n",
    "        self.gear_head = nn.Linear(hidden_size, num_gear_classes)\n",
    "        self.clutch_head = nn.Linear(hidden_size, num_clutch_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shared_features = self.shared(x)\n",
    "        continuous_out = self.continuous_head(shared_features)\n",
    "        accel_brake = torch.sigmoid(continuous_out[:, :2])  # [0, 1]\n",
    "        steering = torch.tanh(continuous_out[:, 2])         # [-1, 1]\n",
    "        continuous_out = torch.cat([accel_brake, steering.unsqueeze(1)], dim=1)\n",
    "        gear_out = self.gear_head(shared_features)\n",
    "        clutch_out = self.clutch_head(shared_features)\n",
    "        return continuous_out, gear_out, clutch_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ece3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_model(model, train_loader, val_loader, num_epochs, device):\n",
    "    criterion_cont = nn.MSELoss()\n",
    "    criterion_disc = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    best_val_loss = float('inf')\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for features, cont_labels, gear_labels, clutch_labels in train_loader:\n",
    "            features = features.to(device)\n",
    "            cont_labels = cont_labels.to(device)\n",
    "            gear_labels = gear_labels.to(device)\n",
    "            clutch_labels = clutch_labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            cont_out, gear_out, clutch_out = model(features)\n",
    "            \n",
    "            loss_cont = criterion_cont(cont_out, cont_labels)\n",
    "            loss_gear = criterion_disc(gear_out, gear_labels)\n",
    "            loss_clutch = criterion_disc(clutch_out, clutch_labels)\n",
    "            loss = loss_cont + loss_gear + loss_clutch\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * features.size(0)\n",
    "        \n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        gear_correct = 0\n",
    "        clutch_correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for features, cont_labels, gear_labels, clutch_labels in val_loader:\n",
    "                features = features.to(device)\n",
    "                cont_labels = cont_labels.to(device)\n",
    "                gear_labels = gear_labels.to(device)\n",
    "                clutch_labels = clutch_labels.to(device)\n",
    "                \n",
    "                cont_out, gear_out, clutch_out = model(features)\n",
    "                loss_cont = criterion_cont(cont_out, cont_labels)\n",
    "                loss_gear = criterion_disc(gear_out, gear_labels)\n",
    "                loss_clutch = criterion_disc(clutch_out, clutch_labels)\n",
    "                loss = loss_cont + loss_gear + loss_clutch\n",
    "                val_loss += loss.item() * features.size(0)\n",
    "                \n",
    "                # Accuracy for Gear/Clutch\n",
    "                _, gear_pred = torch.max(gear_out, 1)\n",
    "                _, clutch_pred = torch.max(clutch_out, 1)\n",
    "                gear_correct += (gear_pred == gear_labels).sum().item()\n",
    "                clutch_correct += (clutch_pred == clutch_labels).sum().item()\n",
    "                total += gear_labels.size(0)\n",
    "        \n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "        gear_acc = gear_correct / total\n",
    "        clutch_acc = clutch_correct / total\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, '\n",
    "              f'Val Loss: {val_loss:.4f}, Gear Acc: {gear_acc:.4f}, Clutch Acc: {clutch_acc:.4f}')\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pt')\n",
    "    \n",
    "    # Plot losses\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, num_epochs+1), train_losses, label='Train Loss')\n",
    "    plt.plot(range(1, num_epochs+1), val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss Over Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig('loss_plot.png')\n",
    "    plt.show()\n",
    "\n",
    "    return train_losses, val_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8154060f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in train_data.csv:\n",
      "['Angle', ' CurrentLapTime', ' Damage', ' DistanceFromStart', ' DistanceCovered', ' FuelLevel', ' LastLapTime', ' Opponent_1', 'RacePosition', ' RPM', ' SpeedX', ' SpeedY', ' SpeedZ', ' Track_1', 'Track_2', 'Track_3', 'Track_4', 'Track_5', 'Track_6', 'Track_7', 'Track_8', 'Track_9', 'Track_10', 'Track_11', 'Track_12', 'Track_13', 'Track_14', 'Track_15', 'Track_16', 'Track_17', 'Track_18', 'Track_19', 'TrackPosition', ' WheelSpinVelocity_1', 'WheelSpinVelocity_2', 'WheelSpinVelocity_3', 'WheelSpinVelocity_4', 'Z', ' Acceleration', 'Braking', 'Clutch', 'Gear', 'Steering']\n",
      "Number of columns: 43\n",
      "\n",
      "Columns in val_data.csv:\n",
      "['Angle', ' CurrentLapTime', ' Damage', ' DistanceFromStart', ' DistanceCovered', ' FuelLevel', ' LastLapTime', ' Opponent_1', 'RacePosition', ' RPM', ' SpeedX', ' SpeedY', ' SpeedZ', ' Track_1', 'Track_2', 'Track_3', 'Track_4', 'Track_5', 'Track_6', 'Track_7', 'Track_8', 'Track_9', 'Track_10', 'Track_11', 'Track_12', 'Track_13', 'Track_14', 'Track_15', 'Track_16', 'Track_17', 'Track_18', 'Track_19', 'TrackPosition', ' WheelSpinVelocity_1', 'WheelSpinVelocity_2', 'WheelSpinVelocity_3', 'WheelSpinVelocity_4', 'Z', ' Acceleration', 'Braking', 'Clutch', 'Gear', 'Steering']\n",
      "Number of columns: 43\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Check train_data.csv\n",
    "train_data = pd.read_csv('../data_generation/data/dirt-2/train_data.csv')\n",
    "print(\"Columns in train_data.csv:\")\n",
    "print(train_data.columns.tolist())\n",
    "print(\"Number of columns:\", len(train_data.columns))\n",
    "\n",
    "# Check val_data.csv\n",
    "val_data = pd.read_csv('../data_generation/data/dirt-2/val_data.csv')\n",
    "print(\"\\nColumns in val_data.csv:\")\n",
    "print(val_data.columns.tolist())\n",
    "print(\"Number of columns:\", len(val_data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667c4730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns\n",
    "sensor_cols = ['Angle', ' CurrentLapTime', ' Damage', ' DistanceFromStart', ' DistanceCovered', \n",
    "                ' FuelLevel', ' LastLapTime', 'RacePosition', ' RPM', \n",
    "               ' SpeedX', ' SpeedY', ' SpeedZ', ' Track_1', 'Track_2', 'Track_3', \n",
    "               'Track_4', 'Track_5', 'Track_6', 'Track_7', 'Track_8', 'Track_9', \n",
    "               'Track_10', 'Track_11', 'Track_12', 'Track_13', 'Track_14', 'Track_15', \n",
    "               'Track_16', 'Track_17', 'Track_18', 'Track_19', 'TrackPosition', \n",
    "                ' WheelSpinVelocity_1', 'WheelSpinVelocity_2', 'WheelSpinVelocity_3', \n",
    "               'WheelSpinVelocity_4', 'Z']\n",
    "continuous_cols = [' Acceleration', 'Braking', 'Steering']\n",
    "discrete_cols = ['Gear', 'Clutch']\n",
    "    \n",
    "# Load datasets\n",
    "train_dataset = TORCSDataset('../data_generation/data/dirt-2/train_data.csv', sensor_cols, continuous_cols, discrete_cols)\n",
    "val_dataset = TORCSDataset('../data_generation/data/dirt-2/val_data.csv', sensor_cols, continuous_cols, discrete_cols)\n",
    "    \n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ba01ef09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "36\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Angle',\n",
       " ' CurrentLapTime',\n",
       " ' Damage',\n",
       " ' DistanceCovered',\n",
       " ' FuelLevel',\n",
       " ' LastLapTime',\n",
       " 'RacePosition',\n",
       " ' RPM',\n",
       " ' SpeedX',\n",
       " ' SpeedY',\n",
       " ' SpeedZ',\n",
       " ' Track_1',\n",
       " 'Track_2',\n",
       " 'Track_3',\n",
       " 'Track_4',\n",
       " 'Track_5',\n",
       " 'Track_6',\n",
       " 'Track_7',\n",
       " 'Track_8',\n",
       " 'Track_9',\n",
       " 'Track_10',\n",
       " 'Track_11',\n",
       " 'Track_12',\n",
       " 'Track_13',\n",
       " 'Track_14',\n",
       " 'Track_15',\n",
       " 'Track_16',\n",
       " 'Track_17',\n",
       " 'Track_18',\n",
       " 'Track_19',\n",
       " 'TrackPosition',\n",
       " ' WheelSpinVelocity_1',\n",
       " 'WheelSpinVelocity_2',\n",
       " 'WheelSpinVelocity_3',\n",
       " 'WheelSpinVelocity_4',\n",
       " 'Z']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(sensor_cols))\n",
    "# print(continuous_cols)\n",
    "\n",
    "print(len(train_dataset.sensor_cols))\n",
    "\n",
    "train_dataset.sensor_cols\n",
    "# val_dataset.sensor_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8793c2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "    # Model parameters\n",
    "input_size = len(sensor_cols)\n",
    "print(input_size)\n",
    "hidden_size = 128\n",
    "num_gear_classes = len(train_dataset.data['Gear'].unique())\n",
    "num_clutch_classes = len(train_dataset.data['Clutch'].unique())\n",
    "    \n",
    "# Initialize model\n",
    "device = torch.device('cpu')\n",
    "model = TORCSNet(input_size, hidden_size, num_gear_classes, num_clutch_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "76b0403d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (128x36 and 37x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 25\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Main execution\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# # Define columns\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# sensor_cols = ['Angle', 'CurrentLapTime', 'Damage', 'DistanceFromStart', 'DistanceCovered', \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m# Train and plot\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m     train_losses, val_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# Load best model\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model.pt\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "Cell \u001b[1;32mIn[17], line 20\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, val_loader, num_epochs, device)\u001b[0m\n\u001b[0;32m     17\u001b[0m clutch_labels \u001b[38;5;241m=\u001b[39m clutch_labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     19\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 20\u001b[0m cont_out, gear_out, clutch_out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m loss_cont \u001b[38;5;241m=\u001b[39m criterion_cont(cont_out, cont_labels)\n\u001b[0;32m     23\u001b[0m loss_gear \u001b[38;5;241m=\u001b[39m criterion_disc(gear_out, gear_labels)\n",
      "File \u001b[1;32md:\\Installed\\ana\\envs\\torcs_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Installed\\ana\\envs\\torcs_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[16], line 19\u001b[0m, in \u001b[0;36mTORCSNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 19\u001b[0m     shared_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshared\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     continuous_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontinuous_head(shared_features)\n\u001b[0;32m     21\u001b[0m     accel_brake \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(continuous_out[:, :\u001b[38;5;241m2\u001b[39m])  \u001b[38;5;66;03m# [0, 1]\u001b[39;00m\n",
      "File \u001b[1;32md:\\Installed\\ana\\envs\\torcs_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Installed\\ana\\envs\\torcs_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\Installed\\ana\\envs\\torcs_env\\lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32md:\\Installed\\ana\\envs\\torcs_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Installed\\ana\\envs\\torcs_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\Installed\\ana\\envs\\torcs_env\\lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (128x36 and 37x128)"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # # Define columns\n",
    "    # sensor_cols = ['Angle', 'CurrentLapTime', 'Damage', 'DistanceFromStart', 'DistanceCovered', \n",
    "    #                'FuelLevel', 'gear_drop', 'LastLapTime', 'RacePosition', 'RPM', \n",
    "    #                'SpeedX', 'SpeedY', 'SpeedZ', 'Track_1', 'Track_2', 'Track_3', \n",
    "    #                'Track_4', 'Track_5', 'Track_6', 'Track_7', 'Track_8', 'Track_9', \n",
    "    #                'Track_10', 'Track_11', 'Track_12', 'Track_13', 'Track_14', 'Track_15', \n",
    "    #                'Track_16', 'Track_17', 'Track_18', 'Track_19', 'TrackPosition', \n",
    "    #                'WheelSpinVelocity_1', 'WheelSpinVelocity_2', 'WheelSpinVelocity_3', \n",
    "    #                'WheelSpinVelocity_4', 'Z']\n",
    "    # continuous_cols = ['Acceleration', 'Braking', 'Steering']\n",
    "    # discrete_cols = ['Gear', 'Clutch']\n",
    "    \n",
    "    # # Load datasets\n",
    "    # train_dataset = TORCSDataset('../data_generation/data/dirt-2/train_data.csv', sensor_cols, continuous_cols, discrete_cols)\n",
    "    # val_dataset = TORCSDataset('../data_generation/data/dirt-2/val_data.csv', sensor_cols, continuous_cols, discrete_cols)\n",
    "    \n",
    "    # train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "    # val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "    \n",
    "\n",
    "    \n",
    "    # Train and plot\n",
    "    train_losses, val_losses = train_model(model, train_loader, val_loader, num_epochs=50, device=device)\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load('best_model.pt'))\n",
    "    print(\"Training complete. Best model saved as 'best_model.pt'. Loss plot saved as 'loss_plot.png'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f493a395",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torcs_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
