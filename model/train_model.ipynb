{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73823c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f581e96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "738c069b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset class\n",
    "class TORCSDataset(Dataset):\n",
    "    def __init__(self, csv_file, sensor_cols, continuous_cols, discrete_cols):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.sensor_cols = [col for col in self.data.columns if col in sensor_cols]\n",
    "        # self.sensor_cols = sensor_cols\n",
    "        self.continuous_cols = [col for col in self.data.columns if col in continuous_cols]\n",
    "        # self.continuous_cols = continuous_cols\n",
    "        self.discrete_cols = [col for col in self.data.columns if col in discrete_cols]\n",
    "        # self.discrete_cols = discrete_cols\n",
    "\n",
    "        self.features = torch.tensor(self.data[self.sensor_cols].values, dtype=torch.float32)\n",
    "        self.steering_labels = torch.tensor(self.data['Steering'].values, dtype=torch.float32).view(-1, 1)\n",
    "        self.accel_labels = torch.tensor(self.data['Acceleration'].values, dtype=torch.long)\n",
    "        self.brake_labels = torch.tensor(self.data['Braking'].values, dtype=torch.long)\n",
    "        self.gear_labels = torch.tensor(self.data['Gear'].values, dtype=torch.long)\n",
    "        self.clutch_labels = torch.tensor(self.data['Clutch'].values, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            self.features[idx],\n",
    "            self.steering_labels[idx],\n",
    "            self.accel_labels[idx],\n",
    "            self.brake_labels[idx],\n",
    "            self.gear_labels[idx],\n",
    "            self.clutch_labels[idx]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3741afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network Model\n",
    "class TORCSNet(nn.Module):\n",
    "    def __init__(self, input_size, num_accel_classes, num_brake_classes, num_gear_classes, num_clutch_classes=2):\n",
    "        super(TORCSNet, self).__init__()\n",
    "        self.shared = nn.Sequential(\n",
    "            # nn.Linear(input_size, 512),\n",
    "            # nn.ReLU(),\n",
    "            # # nn.Dropout(0.2),\n",
    "            # nn.Linear(512, 256),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(0.2),\n",
    "            # nn.Linear(256, 128),        \n",
    "            # # nn.ReLU(),\n",
    "            # # nn.Linear(128, 64),        \n",
    "            # nn.ReLU()\n",
    "            # # nn.Dropout(0.2)\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),  # Add batch norm cautiously\n",
    "            nn.Dropout(0.3),  # Lower dropout to avoid over-regularization\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),  # Optional extra layer\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.steering_head = nn.Linear(64, 1)  # Steering (continuous, [-1, 1])\n",
    "        self.accel_head = nn.Linear(64, num_accel_classes)  # Acceleration (discrete)\n",
    "        self.brake_head = nn.Linear(64, num_brake_classes)  # Braking (discrete)\n",
    "        self.gear_head = nn.Linear(64, num_gear_classes)  # Gear (discrete)\n",
    "        self.clutch_head = nn.Linear(64, num_clutch_classes)  # Clutch (discrete)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        shared = self.shared(x)\n",
    "        steering_out = torch.tanh(self.steering_head(shared))  # [-1, 1]\n",
    "        accel_out = self.accel_head(shared)  # Logits\n",
    "        brake_out = self.brake_head(shared)  # Logits\n",
    "        gear_out = self.gear_head(shared)  # Logits\n",
    "        clutch_out = self.clutch_head(shared)  # Logits\n",
    "        return steering_out, accel_out, brake_out, gear_out, clutch_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b521325f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "# Define columns (update based on preprocessing output)\n",
    "sensor_cols = [\n",
    "        'Angle', 'DistanceCovered', 'LastLapTime', 'RPM',\n",
    "        'SpeedX', 'SpeedY', 'SpeedZ', 'Track_1', 'Track_2', 'Track_3', \n",
    "        'Track_4', 'Track_5', 'Track_6', 'Track_7', 'Track_8', 'Track_9',\n",
    "        'Track_10', 'Track_11', 'Track_12', 'Track_13', 'Track_14', \n",
    "        'Track_15', 'Track_16', 'Track_17', 'Track_18', 'Track_19',\n",
    "        'TrackPosition', 'WheelSpinVelocity_1', 'WheelSpinVelocity_2', \n",
    "        'WheelSpinVelocity_3', 'WheelSpinVelocity_4', 'Z'\n",
    "]  # Placeholder: Update with actual 27 sensors\n",
    "continuous_cols = ['Steering']\n",
    "discrete_cols = ['Acceleration', 'Braking', 'Gear', 'Clutch']\n",
    "    \n",
    "    # Load datasets\n",
    "train_dataset = TORCSDataset('../data_generation/data/train_data_1.csv', sensor_cols, continuous_cols, discrete_cols)\n",
    "val_dataset = TORCSDataset('../data_generation/data/val_data_1.csv', sensor_cols, continuous_cols, discrete_cols)\n",
    "    \n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False)\n",
    "    \n",
    "# Model parameters\n",
    "input_size = len(sensor_cols)\n",
    "print(input_size)\n",
    "print(len(train_dataset.sensor_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92218555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_model(model, train_loader, val_loader, criterion_steering, criterion_accel, criterion_brake, criterion_gear, criterion_clutch, optimizer, num_epochs, device):\n",
    "    best_val_loss = float('inf')\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        accel_correct = 0\n",
    "        brake_correct = 0\n",
    "        gear_correct = 0\n",
    "        clutch_correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for features, steering_labels, accel_labels, brake_labels, gear_labels, clutch_labels in train_loader:\n",
    "            features = features.to(device)\n",
    "            steering_labels = steering_labels.to(device)\n",
    "            accel_labels, brake_labels = accel_labels.to(device), brake_labels.to(device)\n",
    "            gear_labels, clutch_labels = gear_labels.to(device), clutch_labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            steering_out, accel_out, brake_out, gear_out, clutch_out = model(features)\n",
    "            \n",
    "            loss_steering = criterion_steering(steering_out, steering_labels)\n",
    "            loss_accel = criterion_accel(accel_out, accel_labels)\n",
    "            loss_brake = criterion_brake(brake_out, brake_labels)\n",
    "            loss_gear = criterion_gear(gear_out, gear_labels)\n",
    "            loss_clutch = criterion_clutch(clutch_out, clutch_labels)\n",
    "            loss = loss_steering + loss_accel + loss_brake + loss_gear + loss_clutch\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * features.size(0)\n",
    "            accel_correct += (torch.argmax(accel_out, dim=1) == accel_labels).sum().item()\n",
    "            brake_correct += (torch.argmax(brake_out, dim=1) == brake_labels).sum().item()\n",
    "            gear_correct += (torch.argmax(gear_out, dim=1) == gear_labels).sum().item()\n",
    "            clutch_correct += (torch.argmax(clutch_out, dim=1) == clutch_labels).sum().item()\n",
    "            total += gear_labels.size(0)\n",
    "        \n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        accel_acc = accel_correct / total\n",
    "        brake_acc = brake_correct / total\n",
    "        gear_acc = gear_correct / total\n",
    "        clutch_acc = clutch_correct / total\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        accel_correct = 0\n",
    "        brake_correct = 0\n",
    "        gear_correct = 0\n",
    "        clutch_correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for features, steering_labels, accel_labels, brake_labels, gear_labels, clutch_labels in val_loader:\n",
    "                features = features.to(device)\n",
    "                steering_labels = steering_labels.to(device)\n",
    "                accel_labels, brake_labels = accel_labels.to(device), brake_labels.to(device)\n",
    "                gear_labels, clutch_labels = gear_labels.to(device), clutch_labels.to(device)\n",
    "                \n",
    "                steering_out, accel_out, brake_out, gear_out, clutch_out = model(features)\n",
    "                \n",
    "                loss_steering = criterion_steering(steering_out, steering_labels)\n",
    "                loss_accel = criterion_accel(accel_out, accel_labels)\n",
    "                loss_brake = criterion_brake(brake_out, brake_labels)\n",
    "                loss_gear = criterion_gear(gear_out, gear_labels)\n",
    "                loss_clutch = criterion_clutch(clutch_out, clutch_labels)\n",
    "                loss = loss_steering + loss_accel + loss_brake + loss_gear + loss_clutch\n",
    "                \n",
    "                val_loss += loss.item() * features.size(0)\n",
    "                accel_correct += (torch.argmax(accel_out, dim=1) == accel_labels).sum().item()\n",
    "                brake_correct += (torch.argmax(brake_out, dim=1) == brake_labels).sum().item()\n",
    "                gear_correct += (torch.argmax(gear_out, dim=1) == gear_labels).sum().item()\n",
    "                clutch_correct += (torch.argmax(clutch_out, dim=1) == clutch_labels).sum().item()\n",
    "                total += gear_labels.size(0)\n",
    "        \n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_accel_acc = accel_correct / total\n",
    "        val_brake_acc = brake_correct / total\n",
    "        val_gear_acc = gear_correct / total\n",
    "        val_clutch_acc = clutch_correct / total\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "        \n",
    "        print(f\"  Train Loss: {train_loss:.4f}, Accel Acc: {accel_acc:.4f}, Brake Acc: {brake_acc:.4f}, Gear Acc: {gear_acc:.4f}, Clutch Acc: {clutch_acc:.4f}\")\n",
    "        print(f\"  Val Loss: {val_loss:.4f}, Accel Acc: {val_accel_acc:.4f}, Brake Acc: {val_brake_acc:.4f}, Gear Acc: {val_gear_acc:.4f}, Clutch Acc: {val_clutch_acc:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), './model_5/best_model.pt')\n",
    "            print(\"  Saved best model\")\n",
    "    \n",
    "    # Plot loss curves\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Val Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig('./model_5/loss_plot.png')\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17b66fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "num_accel_classes = len(train_dataset.data['Acceleration'].unique())  # Update: e.g., 2 for {0, 1}\n",
    "num_brake_classes = len(train_dataset.data['Braking'].unique())  # Update: e.g., 2 for {0, 1}\n",
    "num_gear_classes = len(train_dataset.data['Gear'].unique())\n",
    "\n",
    "print(num_accel_classes)\n",
    "print(num_brake_classes)\n",
    "print(num_gear_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c95fe2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main execution\n",
    "def main():\n",
    "\n",
    "    num_accel_classes = len(train_dataset.data['Acceleration'].unique())  # Update: e.g., 2 for {0, 1}\n",
    "    num_brake_classes = len(train_dataset.data['Braking'].unique())  # Update: e.g., 2 for {0, 1}\n",
    "    num_gear_classes = len(train_dataset.data['Gear'].unique())  # Update: e.g., 8 for [-1, 0, 1, 2, 3, 4, 5, 6]\n",
    "    num_clutch_classes = 2  # Binary {0, 1}\n",
    "    \n",
    "\n",
    "    \n",
    "    # Initialize model\n",
    "    model = TORCSNet(input_size, num_accel_classes, num_brake_classes, num_gear_classes, num_clutch_classes).to(device)\n",
    "    \n",
    "    # Loss functions\n",
    "    criterion_steering = nn.MSELoss()\n",
    "    \n",
    "    # Compute class weights\n",
    "    accel_counts = train_dataset.data['Acceleration'].value_counts()\n",
    "    accel_class_weights = torch.tensor([1.0 / accel_counts.get(i, 1) for i in range(num_accel_classes)], dtype=torch.float32).to(device)\n",
    "    brake_counts = train_dataset.data['Braking'].value_counts()\n",
    "    brake_class_weights = torch.tensor([1.0 / brake_counts.get(i, 1) for i in range(num_brake_classes)], dtype=torch.float32).to(device)\n",
    "    gear_counts = train_dataset.data['Gear'].value_counts()\n",
    "    gear_class_weights = torch.tensor([1.0 / gear_counts.get(i, 1) for i in range(num_gear_classes)], dtype=torch.float32).to(device)\n",
    "    clutch_counts = train_dataset.data['Clutch'].value_counts()\n",
    "    clutch_class_weights = torch.tensor([1.0 / clutch_counts.get(i, 1) for i in [0, 1]], dtype=torch.float32).to(device)\n",
    "    \n",
    "    criterion_accel = nn.CrossEntropyLoss(weight=accel_class_weights)\n",
    "    criterion_brake = nn.CrossEntropyLoss(weight=brake_class_weights)\n",
    "    criterion_gear = nn.CrossEntropyLoss(weight=gear_class_weights)\n",
    "    criterion_clutch = nn.CrossEntropyLoss(weight=clutch_class_weights)\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "    \n",
    "    # Train model\n",
    "    num_epochs = 50\n",
    "    train_losses, val_losses = train_model(\n",
    "        model, train_loader, val_loader,\n",
    "        criterion_steering, criterion_accel, criterion_brake, criterion_gear, criterion_clutch,\n",
    "        optimizer, num_epochs, device\n",
    "    )\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    test_dataset = TORCSDataset('../data_generation/data/test_data_1.csv', sensor_cols, continuous_cols, discrete_cols)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "    \n",
    "    model.load_state_dict(torch.load('./model_5/best_model.pt'))\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    accel_correct = 0\n",
    "    brake_correct = 0\n",
    "    gear_correct = 0\n",
    "    clutch_correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for features, steering_labels, accel_labels, brake_labels, gear_labels, clutch_labels in test_loader:\n",
    "            features = features.to(device)\n",
    "            steering_labels = steering_labels.to(device)\n",
    "            accel_labels, brake_labels = accel_labels.to(device), brake_labels.to(device)\n",
    "            gear_labels, clutch_labels = gear_labels.to(device), clutch_labels.to(device)\n",
    "            \n",
    "            steering_out, accel_out, brake_out, gear_out, clutch_out = model(features)\n",
    "            \n",
    "            loss_steering = criterion_steering(steering_out, steering_labels)\n",
    "            loss_accel = criterion_accel(accel_out, accel_labels)\n",
    "            loss_brake = criterion_brake(brake_out, brake_labels)\n",
    "            loss_gear = criterion_gear(gear_out, gear_labels)\n",
    "            loss_clutch = criterion_clutch(clutch_out, clutch_labels)\n",
    "            loss = loss_steering + loss_accel + loss_brake + loss_gear + loss_clutch\n",
    "            \n",
    "            test_loss += loss.item() * features.size(0)\n",
    "            accel_correct += (torch.argmax(accel_out, dim=1) == accel_labels).sum().item()\n",
    "            brake_correct += (torch.argmax(brake_out, dim=1) == brake_labels).sum().item()\n",
    "            gear_correct += (torch.argmax(gear_out, dim=1) == gear_labels).sum().item()\n",
    "            clutch_correct += (torch.argmax(clutch_out, dim=1) == clutch_labels).sum().item()\n",
    "            total += gear_labels.size(0)\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accel_acc = accel_correct / total\n",
    "    brake_acc = brake_correct / total\n",
    "    gear_acc = gear_correct / total\n",
    "    clutch_acc = clutch_correct / total\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Accel Acc: {accel_acc:.4f}, Brake Acc: {brake_acc:.4f}, Gear Acc: {gear_acc:.4f}, Clutch Acc: {clutch_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c647122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:\n",
      "  Train Loss: 2.1015, Accel Acc: 0.7139, Brake Acc: 0.7859, Gear Acc: 0.6800, Clutch Acc: 0.9341\n",
      "  Val Loss: 1.8601, Accel Acc: 0.7309, Brake Acc: 0.8074, Gear Acc: 0.7529, Clutch Acc: 0.9409\n",
      "  Saved best model\n",
      "Epoch 2/50:\n",
      "  Train Loss: 1.7794, Accel Acc: 0.7530, Brake Acc: 0.8259, Gear Acc: 0.7439, Clutch Acc: 0.9386\n",
      "  Val Loss: 1.6641, Accel Acc: 0.7692, Brake Acc: 0.7996, Gear Acc: 0.7834, Clutch Acc: 0.8861\n",
      "  Saved best model\n",
      "Epoch 3/50:\n",
      "  Train Loss: 1.7158, Accel Acc: 0.7625, Brake Acc: 0.8340, Gear Acc: 0.7561, Clutch Acc: 0.9388\n",
      "  Val Loss: 1.9971, Accel Acc: 0.6731, Brake Acc: 0.7985, Gear Acc: 0.7468, Clutch Acc: 0.8400\n",
      "Epoch 4/50:\n",
      "  Train Loss: 1.6423, Accel Acc: 0.7691, Brake Acc: 0.8463, Gear Acc: 0.7724, Clutch Acc: 0.9293\n",
      "  Val Loss: 1.8388, Accel Acc: 0.7458, Brake Acc: 0.8939, Gear Acc: 0.7519, Clutch Acc: 0.9505\n",
      "Epoch 5/50:\n",
      "  Train Loss: 1.5948, Accel Acc: 0.7744, Brake Acc: 0.8527, Gear Acc: 0.7772, Clutch Acc: 0.9329\n",
      "  Val Loss: 1.5933, Accel Acc: 0.8127, Brake Acc: 0.8986, Gear Acc: 0.7746, Clutch Acc: 0.9507\n",
      "  Saved best model\n",
      "Epoch 6/50:\n",
      "  Train Loss: 1.5776, Accel Acc: 0.7794, Brake Acc: 0.8543, Gear Acc: 0.7817, Clutch Acc: 0.9273\n",
      "  Val Loss: 1.9880, Accel Acc: 0.6993, Brake Acc: 0.7391, Gear Acc: 0.7809, Clutch Acc: 0.9049\n",
      "Epoch 7/50:\n",
      "  Train Loss: 1.5491, Accel Acc: 0.7808, Brake Acc: 0.8553, Gear Acc: 0.7864, Clutch Acc: 0.9311\n",
      "  Val Loss: 1.7962, Accel Acc: 0.8215, Brake Acc: 0.8969, Gear Acc: 0.7435, Clutch Acc: 0.9753\n",
      "Epoch 8/50:\n",
      "  Train Loss: 1.5437, Accel Acc: 0.7814, Brake Acc: 0.8576, Gear Acc: 0.7878, Clutch Acc: 0.9308\n",
      "  Val Loss: 2.2559, Accel Acc: 0.8041, Brake Acc: 0.9134, Gear Acc: 0.7060, Clutch Acc: 0.9552\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[26], line 37\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m     36\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[1;32m---> 37\u001b[0m train_losses, val_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion_steering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion_accel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion_brake\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion_gear\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion_clutch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Evaluate on test set\u001b[39;00m\n\u001b[0;32m     44\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m TORCSDataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data_generation/data/test_data_1.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, sensor_cols, continuous_cols, discrete_cols)\n",
      "Cell \u001b[1;32mIn[25], line 34\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, val_loader, criterion_steering, criterion_accel, criterion_brake, criterion_gear, criterion_clutch, optimizer, num_epochs, device)\u001b[0m\n\u001b[0;32m     31\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_steering \u001b[38;5;241m+\u001b[39m loss_accel \u001b[38;5;241m+\u001b[39m loss_brake \u001b[38;5;241m+\u001b[39m loss_gear \u001b[38;5;241m+\u001b[39m loss_clutch\n\u001b[0;32m     33\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 34\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m features\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     37\u001b[0m accel_correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39margmax(accel_out, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m accel_labels)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32md:\\Installed\\ana\\envs\\torcs_env\\lib\\site-packages\\torch\\optim\\optimizer.py:472\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m cast(Optimizer, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    471\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 472\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m    473\u001b[0m     \u001b[38;5;66;03m# call optimizer step pre hooks\u001b[39;00m\n\u001b[0;32m    474\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pre_hook \u001b[38;5;129;01min\u001b[39;00m chain(\n\u001b[0;32m    475\u001b[0m         _global_optimizer_pre_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[0;32m    476\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_pre_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[0;32m    477\u001b[0m     ):\n\u001b[0;32m    478\u001b[0m         result \u001b[38;5;241m=\u001b[39m pre_hook(\u001b[38;5;28mself\u001b[39m, args, kwargs)\n",
      "File \u001b[1;32md:\\Installed\\ana\\envs\\torcs_env\\lib\\site-packages\\torch\\autograd\\profiler.py:733\u001b[0m, in \u001b[0;36mrecord_function.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    732\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 733\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecord \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprofiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_record_function_enter_new\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\n\u001b[0;32m    735\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32md:\\Installed\\ana\\envs\\torcs_env\\lib\\site-packages\\torch\\_ops.py:1116\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_torchbind_op_overload \u001b[38;5;129;01mand\u001b[39;00m _must_dispatch_in_python(args, kwargs):\n\u001b[0;32m   1115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _call_overload_packet_from_python(\u001b[38;5;28mself\u001b[39m, args, kwargs)\n\u001b[1;32m-> 1116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(kwargs \u001b[38;5;129;01mor\u001b[39;00m {}))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60183a80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torcs_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
